{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make your data accessible to the GeoAnalytics Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting, storing, managing, and analyzing large quantities of numbers, figures, and files is not a new business activity. However, referring to these numbers, figures, and files as big data is relatively recent.\n",
    "\n",
    "The GeoAnalytics Server expands your ArcGIS Enterprise deployment, providing functionality and services to process and analyze big data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the GeoAnalytics tools, your data needs to be in one of the following formats:\n",
    "\n",
    "- [Feature layers](https://developers.arcgis.com/python/guide/working-with-feature-layers-and-features/) (hosted, hosted feature layer views, and from feature services)\n",
    "- [Feature collections](https://developers.arcgis.com/python/api-reference/arcgis.features.toc.html#featurecollection)\n",
    "- [Big data file shares](https://gis.fema.gov/arcgis/help/en/portal/latest/use/what-is-a-big-data-file-share.htm) registered with ArcGIS GeoAnalytics Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Please refer to the [features module](https://developers.arcgis.com/python/guide/features-module/) guide to understand more about feature layers and feature collections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big data file shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GeoAnalytics server allows you to register datasets in a format called a [big data file share](http://enterprise.arcgis.com/en/server/latest/get-started/windows/what-is-a-big-data-file-share.htm). Big data file shares are items on your Web GIS, and can reference data in any of the following data sources:\n",
    " - File Share - a directory of datasets stored locally or shared across a network\n",
    " - HDFS - a [Hadoop Distributed File System](https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html#Introduction) directory of datasets\n",
    " - [Apache Hive](https://hive.apache.org/) - a metastore database\n",
    " - Cloud Store - an [Azure Blob Storage](https://azure.microsoft.com/en-us/services/storage/blobs/) container or [Amazon Web Services S3 bucket](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucket.html) \n",
    "\n",
    "Storing your data in a big data file share datastore benefits you because:\n",
    " - The GeoAnalytics tools read your data only when they are executed, which allows you to update or add data to these locations.\n",
    " - You can use partitioned data as a single dataset.\n",
    " - Big data file shares are flexible in how time and geometry are defined, allowing data in multiple formats in a single dataset.\n",
    " \n",
    "When writing results to a big data file share, you can use the following output GeoAnalytics Tools:\n",
    "\n",
    "- File share\n",
    "- HDFS\n",
    "- Cloud store\n",
    "\n",
    "The following file types are supported as datasets for input and output in big data file shares:\n",
    "\n",
    "- Delimited files (such as .csv, .tsv, and .txt)\n",
    "- Shapefiles (.shp)\n",
    "- Parquet files (.gz.parquet)\n",
    "- ORC files (orc.crc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store data where all ArcGIS Server machines can access it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To allow your ArcGIS Server sites to access the data resources you want to publish, all machines in the ArcGIS Server site must have access to the resource. For example, when you publish a map as a service, the map and all the data for the map's layers must be accessible to all ArcGIS Server machines.\n",
    "\n",
    "You need to do the following to make your data accessible to ArcGIS Server:\n",
    "\n",
    "[Store your data in a location that all machines in your ArcGIS Server site can access](https://enterprise.arcgis.com/en/server/latest/install/linux/making-your-data-accessible-to-arcgis-server.htm#GUID-72AAE08B-60B2-4C3D-BB85-128F8AB5C3DB).\n",
    "\n",
    "[Grant permissions](https://enterprise.arcgis.com/en/server/latest/install/linux/making-your-data-accessible-to-arcgis-server.htm#GUID-58A12575-36EC-4FD1-A5D8-A34FBE957736) to allow ArcGIS Server to access the data.\n",
    "If your data is stored in a folder or a database that you access using operating system authentication, you must grant the ArcGIS Server account permissions to these locations. The ArcGIS Server account is the account you used to install ArcGIS Server, not the primary site administrator specified when the ArcGIS Server site was created.\n",
    "If your data is stored in a database that you access using database authentication, the database user you provide when registering the database must have permissions to the data.\n",
    "\n",
    "[Register your data store with the ArcGIS Server site](https://enterprise.arcgis.com/en/server/latest/install/linux/making-your-data-accessible-to-arcgis-server.htm#ESRI_SECTION1_2B393373CC0D48518596D3380A972B8A)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare your data to be registered as big data file share"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To register a file share or an HDFS, you need to format your datasets as subfolders within a single parent folder and register the parent folder. This parent folder becomes a `datastore`, and each subfolder becomes a `dataset`. For instance, to register 2 datasets representing earthquakes and hurricanes, your folder hierarchy would look like below:\n",
    "```\n",
    "|---FileShareFolder         <-- register as a datastore\n",
    "   |---Earthquakes          <-- dataset 1\n",
    "      |---1960              \n",
    "         |---01_1960.csv\n",
    "         |---02_1960.csv\n",
    "      |---1961              \n",
    "         |---01_1961.csv\n",
    "         |---02_1961.csv\n",
    "   |---Hurricanes           <-- dataset 2\n",
    "      |---atlantic_hur.shp\n",
    "      |---pacific_hur.shp\n",
    "```\n",
    "Learn more about preparing your big data file share datasets [here](http://server.arcgis.com/en/server/latest/get-started/windows/what-is-a-big-data-file-share.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to enterprise GIS\n",
    "from arcgis.gis import GIS\n",
    "import arcgis.geoanalytics\n",
    "portal_gis = GIS(\"your_enterprise_portal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ensuring your GIS supports GeoAnalytics</b>\n",
    "\n",
    "Before executing a tool, we need to ensure an ArcGIS Enterprise GIS is set up with a licensed GeoAnalytics server. To do so, call the [`is_supported()`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.geoanalytics.toc.html#is-supported) method after connecting to your Enterprise portal. See the [Components of ArcGIS URLs](http://enterprise.arcgis.com/en/portal/latest/administer/linux/components-of-arcgis-urls.htm) documentation for details on the urls to enter in the [`GIS`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.gis.toc.html#gis) parameters based on your particular Enterprise configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that GeoAnalytics is supported \n",
    "arcgis.geoanalytics.is_supported()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering big data file shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`get_datastores()`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.geoanalytics.toc.html#get-datastores) method of the `geoanalytics` module returns a [`DatastoreManager`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.gis.toc.html#datastoremanager) object that lets you search for and manage the big data file share items as Python API  [`Datastore`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.gis.toc.html#datastore) objects on your GeoAnalytics server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatastoreManager for https://pythonapi.playground.esri.com/ga/admin>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdata_datastore_manager = arcgis.geoanalytics.get_datastores()\n",
    "bigdata_datastore_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data prepared above can be stored to one of the following locations based on the size of your data, the number of people who will access the web service, and how frequently the data changes.\n",
    "\n",
    "- Store data locally on each ArcGIS Server machine\n",
    "- Store data in a shared directory\n",
    "- Store data in a database\n",
    "- Store caches, imagery, and big data files in a cloud storage container\n",
    "\n",
    "Later, We will learn how to register a cloud store as datastore for registering your data as big data file share. Next, we will learn how to register data from a local/shared directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Register the cloud store with your GeoAnalytics Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your data is stored on a cloud store, you can register it as a DataStore using the `add_cloudstore` function. This function can register cloud store as a DataStore for Azure Data Lake Storage, Amazon, Alibaba, or Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_dict = {\"accessKeyId\":\"<provide key here>\",\n",
    "             \"secretAccessKey\":\"<provide secret key here>\",\n",
    "             \"region\":\"<provide region here>\",\n",
    "             \"defaultEndpointsProtocol\":\"<probide https or http here>\",\n",
    "             \"credentialType\":\"accesskey\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "conn_str = json.dumps(conn_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created cloud store for cloud_store\n"
     ]
    }
   ],
   "source": [
    "datastore_obj = bigdata_datastore_manager.add_cloudstore(name='cloud_store', \n",
    "                                         conn_str=conn_str, \n",
    "                                         object_store=\"esri-delhi-store\", \n",
    "                                         provider='amazon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cloudStores/cloud_store'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datastore_obj.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Register the data on cloud store as a big data file share"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can register your data as a big data file share using the `add_bigdata()` method on a `DatastoreManager` object. Ensure the datasets are stored in a format compatible with the GeoAnalytics server, as demonstrated earlier in this guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "item = bigdata_datastore_manager.add_bigdata(\"Name_of_big_data_file_share\", r\"\\\\<file_share_path>\\<big_data_folder>\")\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Big Data file share for ServiceCallsOrleans\n"
     ]
    }
   ],
   "source": [
    "data_item1 = bigdata_datastore_manager.add_bigdata(name=\"ServiceCallsOrleans\", \n",
    "                                                  server_path=data_item.path, \n",
    "                                                  connection_type='dataStore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Register data using a local directory or shared directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your data lies locally on your system, you can directly register it by passing the shared path of that data into the `add_bigdata` function. It is recommended that you use shared paths to allow other servers to access the data while running operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Big Data file share for ServiceCallsOrleans\n"
     ]
    }
   ],
   "source": [
    "data_item2 = bigdata_datastore_manager.add_bigdata(\"ServiceCallsOrleans\", r\"\\\\machinename\\datastore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more about how to register other formats as a file share, for example HDFS or Hive, click [here](https://enterprise.arcgis.com/en/server/latest/manage-data/windows/registering-your-data-with-arcgis-server-using-manager.htm#ESRI_SECTION1_0D55682C9D6E48E7857852A9E2D5D189)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting big data file shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully registered your data with ArcGIS Geoanalytics Server to run Geoanalytics tools, it's time to inspect the file share to verify that your data is registered in a desired format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Searching for big data file shares on datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the [`search()`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.gis.toc.html#arcgis.gis.DatastoreManager.search) method on a `DatastoreManager` object to search for `Datastores`. Observe in the output below the item titled `ServiceCallsOrleans`. As illustrated in the example file structure above is registered as a big data file share in the portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Datastore title:\"/bigDataFileShares/NYC_taxi_data15\" type:\"bigDataFileShare\">,\n",
       " <Datastore title:\"/bigDataFileShares/all_hurricanes\" type:\"bigDataFileShare\">,\n",
       " <Datastore title:\"/bigDataFileShares/NYCdata\" type:\"bigDataFileShare\">,\n",
       " <Datastore title:\"/bigDataFileShares/hurricanes_1848_1900\" type:\"bigDataFileShare\">,\n",
       " <Datastore title:\"/bigDataFileShares/ServiceCallsOrleans\" type:\"bigDataFileShare\">,\n",
       " <Datastore title:\"/bigDataFileShares/hurricanes_dask_csv\" type:\"bigDataFileShare\">,\n",
       " <Datastore title:\"/bigDataFileShares/hurricanes_dask_shp\" type:\"bigDataFileShare\">,\n",
       " <Datastore title:\"/cloudStores/cloud_store\" type:\"cloudStore\">]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdata_fileshares = bigdata_datastore_manager.search()\n",
    "bigdata_fileshares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Get datasets from a big data file share datastore</b>\n",
    "\n",
    "Let's use the `datasets` property on a `Datastore` object to find out how many datasets are available and then list them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_share_folder = bigdata_fileshares[4]\n",
    "file_share_datasets = file_share_folder.datasets\n",
    "len(file_share_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 0:   yearly_calls\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(file_share_datasets)):\n",
    "    print(\"{:<10}{:<3}{}\".format(\"Dataset \" + str(i) + \":\", \"\", file_share_datasets[i]['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'yearly_calls',\n",
       " 'format': {'quoteChar': '\"',\n",
       "  'fieldDelimiter': ',',\n",
       "  'hasHeaderRow': True,\n",
       "  'encoding': 'UTF-8',\n",
       "  'escapeChar': '\"',\n",
       "  'recordTerminator': '\\n',\n",
       "  'type': 'delimited',\n",
       "  'extension': 'csv'},\n",
       " 'schema': {'fields': [{'name': 'NOPD_Item', 'type': 'esriFieldTypeString'},\n",
       "   {'name': 'Type_', 'type': 'esriFieldTypeString'},\n",
       "   {'name': 'TypeText', 'type': 'esriFieldTypeString'},\n",
       "   {'name': 'Priority', 'type': 'esriFieldTypeString'},\n",
       "   {'name': 'MapX', 'type': 'esriFieldTypeDouble'},\n",
       "   {'name': 'MapY', 'type': 'esriFieldTypeDouble'},\n",
       "   {'name': 'TimeCreate', 'type': 'esriFieldTypeString'},\n",
       "   {'name': 'TimeDispatch', 'type': 'esriFieldTypeString'},\n",
       "   {'name': 'TimeArrive', 'type': 'esriFieldTypeString'},\n",
       "   {'name': 'TimeClosed', 'type': 'esriFieldTypeString'},\n",
       "   {'name': 'Disposition', 'type': 'esriFieldTypeString'},\n",
       "   {'name': 'DispositionText', 'type': 'esriFieldTypeString'},\n",
       "   {'name': 'BLOCK_ADDRESS', 'type': 'esriFieldTypeString'},\n",
       "   {'name': 'Zip', 'type': 'esriFieldTypeBigInteger'},\n",
       "   {'name': 'PoliceDistrict', 'type': 'esriFieldTypeBigInteger'},\n",
       "   {'name': 'Location', 'type': 'esriFieldTypeString'}]},\n",
       " 'geometry': {'geometryType': 'esriGeometryPoint',\n",
       "  'spatialReference': {'wkid': 102682, 'latestWkid': 3452},\n",
       "  'fields': [{'name': 'MapX', 'formats': ['x']},\n",
       "   {'name': 'MapY', 'formats': ['y']}]},\n",
       " 'time': {'timeType': 'instant',\n",
       "  'timeReference': {'timeZone': 'UTC'},\n",
       "  'fields': [{'name': 'TimeCreate', 'formats': ['MM/dd/yyyy hh:mm:ss a']}]}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's view the json schema of the calls dataset for a sample\n",
    "file_share_datasets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Get path of the big data file share item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/bigDataFileShares/ServiceCallsOrleans'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_share_folder.datapath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Check if the data is accessible to all Geoanalytics servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can validate the data store connection to confirm that the ArcGIS Server site can communicate with a data store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_share_folder.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If ArcGIS Server did not connect, confirm that the data store is available. For example, ensure that the machine the data store is on is running and has network connectivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Get schema of the data</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a big data file share is created, the GeoAnalytics server samples the datasets to generate a [manifest](https://enterprise.arcgis.com/en/server/latest/get-started/windows/understanding-the-big-data-file-share-manifest.htm) that outlines the data schema and specifies any time and geometry fields. A query of the resulting manifest returns each dataset's schema. This process can take a few minutes depending on the size of your data. Once processed, querying the manifest property returns the schema of the datasets in your big data file share.\n",
    "\n",
    "To learn more about the big data file share manifest, see [Understanding the big data file share manifest](https://enterprise.arcgis.com/en/geoanalytics/latest/perform-analysis/understanding-the-big-data-file-share-manifest.htm) in the ArcGIS Server help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datasets': [{'name': 'calls',\n",
       "   'format': {'quoteChar': '\"',\n",
       "    'fieldDelimiter': ',',\n",
       "    'hasHeaderRow': True,\n",
       "    'encoding': 'UTF-8',\n",
       "    'escapeChar': '\"',\n",
       "    'recordTerminator': '\\n',\n",
       "    'type': 'delimited',\n",
       "    'extension': 'csv'},\n",
       "   'schema': {'fields': [{'name': 'NOPD_Item', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'Type_', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'TypeText', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'Priority', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'MapX', 'type': 'esriFieldTypeDouble'},\n",
       "     {'name': 'MapY', 'type': 'esriFieldTypeDouble'},\n",
       "     {'name': 'TimeCreate', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'TimeDispatch', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'TimeArrive', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'TimeClosed', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'Disposition', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'DispositionText', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'BLOCK_ADDRESS', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'Zip', 'type': 'esriFieldTypeBigInteger'},\n",
       "     {'name': 'PoliceDistrict', 'type': 'esriFieldTypeBigInteger'},\n",
       "     {'name': 'Location', 'type': 'esriFieldTypeString'}]},\n",
       "   'geometry': {'geometryType': 'esriGeometryPoint',\n",
       "    'spatialReference': {'wkid': 4326},\n",
       "    'fields': [{'name': 'MapX', 'formats': ['x']},\n",
       "     {'name': 'MapY', 'formats': ['y']}]},\n",
       "   'time': {'timeType': 'instant',\n",
       "    'timeReference': {'timeZone': 'UTC'},\n",
       "    'fields': [{'name': 'TimeCreate',\n",
       "      'formats': ['MM/dd/yyyy hh:mm:ss a']}]}}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifest = file_share_folder.manifest\n",
    "manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify a big data file share"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a big data catalog service is created, a manifest for the input data is automatically generated and uploaded to the GeoAnalytics Server site where you registered the data. The process of generating a manifest may not always correctly estimate the fields representing geometry and time, and you may need to apply edits. To edit a manifest, follow the steps with UI [Edit big data file share manifests in Manager](https://enterprise.arcgis.com/en/geoanalytics/latest/perform-analysis/edit-big-data-file-share-manifests-in-manager.htm). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example here, the spatial reference of the dataset is set to 4326, but we know this data is from New Orleans, Louisiana, and is actually stored in the [Louisiana State Plane Coordinate System](https://spatialreference.org/ref/esri/102682/html/). We need to edit the manifest with the correct spatial reference: {\"wkid\": 102682, \"latestWkid\": 3452}. Knowing the location of this data and the coordinate system to which it belongs, we will edit our manifest. This will set the correct spatial reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest['datasets'][0]['geometry']['spatialReference'] = { \"wkid\": 102682, \"latestWkid\": 3452 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_share_folder.manifest = manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datasets': [{'name': 'calls',\n",
       "   'format': {'quoteChar': '\"',\n",
       "    'fieldDelimiter': ',',\n",
       "    'hasHeaderRow': True,\n",
       "    'encoding': 'UTF-8',\n",
       "    'escapeChar': '\"',\n",
       "    'recordTerminator': '\\n',\n",
       "    'type': 'delimited',\n",
       "    'extension': 'csv'},\n",
       "   'schema': {'fields': [{'name': 'NOPD_Item', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'Type_', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'TypeText', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'Priority', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'MapX', 'type': 'esriFieldTypeDouble'},\n",
       "     {'name': 'MapY', 'type': 'esriFieldTypeDouble'},\n",
       "     {'name': 'TimeCreate', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'TimeDispatch', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'TimeArrive', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'TimeClosed', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'Disposition', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'DispositionText', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'BLOCK_ADDRESS', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'Zip', 'type': 'esriFieldTypeBigInteger'},\n",
       "     {'name': 'PoliceDistrict', 'type': 'esriFieldTypeBigInteger'},\n",
       "     {'name': 'Location', 'type': 'esriFieldTypeString'}]},\n",
       "   'geometry': {'geometryType': 'esriGeometryPoint',\n",
       "    'spatialReference': {'wkid': 102682, 'latestWkid': 3452},\n",
       "    'fields': [{'name': 'MapX', 'formats': ['x']},\n",
       "     {'name': 'MapY', 'formats': ['y']}]},\n",
       "   'time': {'timeType': 'instant',\n",
       "    'timeReference': {'timeZone': 'UTC'},\n",
       "    'fields': [{'name': 'TimeCreate',\n",
       "      'formats': ['MM/dd/yyyy hh:mm:ss a']}]}}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_share_folder.manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can regenerate a manifest if you have added new data or if you have uploaded a hints file using the edit resource.\n",
    "file_share_folder.regenerate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you are ready to run tools available in `arcgis.geoanalytics` module. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the output templates for a big data file share"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you choose to use the big data file share as an output location, output templates are automatically generated. These templates outline the formatting of output analysis results, such as the file type, and how time and geometry will be registered. If you want to modify the geometry or time formatting, or add or delete templates, you can modify the templates. To edit the output templates, follow the steps in [Edit big data file share manifests in Manager](https://enterprise.arcgis.com/en/geoanalytics/latest/perform-analysis/edit-big-data-file-share-manifests-in-manager.htm). Learn more about output templates in the [Output templates in a big data file share](https://enterprise.arcgis.com/en/geoanalytics/latest/perform-analysis/output-templates-in-a-big-data-file-share.htm) topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this guide, we have covered concepts on registering datastores and big data file shares, inspecting a big data file share, modifying data schema, and more. In this next guide, we will perform analysis with the published data and learn more about tools available in the geoanalytics module."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
